{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured JSON Output from Image Analysis\n",
    "Run this within the virtual environment **(env_ollama)**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matthias/Desktop/MachineLearning/Ollama_Udemy/env_ollama/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **ChatGPT's improved version** of this file since the original course version didn't work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"summary\": \"A breathtaking sunset scene with the iconic Eiffel Tower in the background, surrounded by a vibrant cityscape.\",\n",
      "  \"scene\": \"The Eiffel Tower stands tall amidst a bustling city, with a serene river flowing through the foreground. The sky is painted with hues of orange and pink, as the sun sets behind the tower.\",\n",
      "  \"colors\": [\n",
      "    \"orange\",\n",
      "    \"pink\",\n",
      "    \"blue\",\n",
      "    \"yellow\",\n",
      "    \"green\",\n",
      "    \"brown\",\n",
      "    \"gray\",\n",
      "    \"white\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "class ImageDescription(BaseModel):\n",
    "    summary: str\n",
    "    scene: str\n",
    "    colors: List[str] = Field(default_factory=list)\n",
    "\n",
    "path = \"/home/matthias/Desktop/MachineLearning/Ollama_Udemy/Images/paris.jpg\"\n",
    "\n",
    "def call_ollama(num_predict: int) -> str:\n",
    "    resp = chat(\n",
    "        model=\"llama3.2-vision\",\n",
    "        format=ImageDescription.model_json_schema(),\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Return ONLY a single JSON object matching the schema.\\n\"\n",
    "                    \"Be concise to fit the output limit:\\n\"\n",
    "                    \"- summary: max 1 sentence\\n\"\n",
    "                    \"- scene: max 2 sentences\\n\"\n",
    "                    \"- colors: 3 to 8 simple color words\\n\"\n",
    "                    \"No markdown, no commentary.\"\n",
    "                ),\n",
    "                \"images\": [path],\n",
    "            }\n",
    "        ],\n",
    "        options={\n",
    "            \"temperature\": 0,\n",
    "            \"num_predict\": num_predict,\n",
    "        },\n",
    "    )\n",
    "    return resp.message.content.strip()\n",
    "\n",
    "def parse_json_or_raise(raw: str) -> ImageDescription:\n",
    "    # 1) Try direct JSON parse\n",
    "    try:\n",
    "        return ImageDescription.model_validate_json(raw)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 2) Try extracting the largest {...} block\n",
    "    start = raw.find(\"{\")\n",
    "    end = raw.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        candidate = raw[start:end+1]\n",
    "        return ImageDescription.model_validate(json.loads(candidate))\n",
    "    # 3) Nothing usable\n",
    "    raise ValueError(f\"Model did not return valid JSON. First 300 chars:\\n{raw[:300]}\")\n",
    "\n",
    "# Try with increasing budgets\n",
    "last_raw = None\n",
    "for budget in (1024, 2048, 4096):\n",
    "    last_raw = call_ollama(num_predict=budget)\n",
    "    try:\n",
    "        image_description = parse_json_or_raise(last_raw)\n",
    "        break\n",
    "    except Exception:\n",
    "        image_description = None\n",
    "\n",
    "if image_description is None:\n",
    "    # If we still fail, show what we got to debug.\n",
    "    raise RuntimeError(\n",
    "        \"Could not parse valid JSON from the model even after retries.\\n\"\n",
    "        f\"Last raw output (first 500 chars):\\n{last_raw[:500]}\"\n",
    "    )\n",
    "\n",
    "print(image_description.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Paris](../../Images/paris.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\checkmark$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
